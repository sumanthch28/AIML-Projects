{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "miniproject_1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYFKmGqpWytS"
      },
      "source": [
        "# Problem :\n",
        "\n",
        "IMDB movie review sentiment classification problem. Each movie review is a variable sequence of words and the sentiment of each movie review must be classified. The IMDB Movie Review Dataset contains 25,000 highly-polar movie reviews (good or bad) for training and the same amount again for testing. The problem is to determine whether a given movie review has a positive or negative sentiment. Keras provides access to the IMDB dataset built-in. The imdb.load_data() function allows you to load the dataset in a format that is ready for use in neural network and deep learning models. The words have been replaced by integers that indicate the ordered frequency of each word in the dataset. The sentences in each review are therefore comprised of a sequence of integers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCikxBAfWytc"
      },
      "source": [
        "# Why CNN with LSTM for text Classifcation\n",
        "\n",
        "CNNs are generally used in computer vision, however they’ve recently been applied to various NLP tasks and the results were promising.\n",
        "Let’s briefly see what happens when we use CNN on text data through a diagram.The result of each convolution will fire when a special pattern is detected. By varying the size of the kernels and concatenating their outputs, you’re allowing yourself to detect patterns of multiples sizes (2, 3, or 5 adjacent words).Patterns could be expressions (word ngrams?) like “I hate”, “very good” and therefore CNNs can identify them in the sentence regardless of their position.\n",
        "Recurrent neural networks can obtain context information but the order of words will lead to bias; the text analysis method based on Convolutional neural network (CNN) can obtain important features of text through pooling but it is difficult to obtain contextual information which can be leverage using LSTM. So using the combination of CNN with LSTM could give us some intresting results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoVPi1KzWytd"
      },
      "source": [
        "# Develop an text classification model based on CNN + LSTM in Keras.\n",
        "\n",
        "In this assignment, you will have to train two Text classification:\n",
        "1) LSTM based Text Classification\n",
        "2) CNN + LSTM based Text Classification\n",
        "\n",
        "After training the two different classification, you have to compare the accuracy on both of the model trained and report the best accuracy for which of them.\n",
        "\n",
        "This notebook is divided into six parts. Total : [8 Marks]\n",
        "\n",
        "1. Import the required Libraires [1 Mark]\n",
        "2. Implement the LSTM model [2 Marks]\n",
        "3. Calculate the LSTM model accuracy [1 Mark]\n",
        "4. Implement the CNN + LSTM [3 Marks]\n",
        "5. Calculate the CNN + LSTM model accuracy [1 Mark]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtCXGq8CWytd"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import imdb\n",
        "\n",
        "#import the required library\n",
        "\n",
        "# Student will have to code here\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "# Students will end their code here"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVRC4zJlWytg",
        "outputId": "2a104fb9-8d67-4433-96bb-fa535f70cff7"
      },
      "source": [
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 10000\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.load.__defaults__=(None, True, True, 'ASCII')\n",
        "\n",
        "# call load_data with allow_pickle implicitly set to true\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
        "\n",
        "X_train,X_cv,y_train,y_cv = train_test_split(X_train,y_train,test_size = 0.2)\n",
        "print(\"Shape of train data:\", X_train.shape)\n",
        "print(\"Shape of Test data:\", X_test.shape)\n",
        "print(\"Shape of CV data:\", X_cv.shape)\n",
        "\n",
        "# truncate and pad input sequences\n",
        "max_review_length = 600\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "X_cv = sequence.pad_sequences(X_cv,maxlen=max_review_length)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shape of train data: (20000,)\n",
            "Shape of Test data: (25000,)\n",
            "Shape of CV data: (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFkmDpEHWyth",
        "outputId": "9c7199d2-c10f-4e8f-8c1b-411afaba83ae"
      },
      "source": [
        "y_train[0:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W03j6_-LWyth",
        "outputId": "3fb04900-e006-4a67-e892-3ee916143d69"
      },
      "source": [
        "# Decoding the data coded data of IMDB ( Data Understanding )\n",
        "index = imdb.get_word_index()\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in X_train[0]] )\n",
        "print(decoded) \n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # the unseen is done in a style more like old hollywood mysteries than a horror show the film is somewhat slow but lots of bizarre imagery keeps it the film alive and watchable the basic idea of young girls stalked by something in the basement is old but good acting and production make the movie worth watching the movie is notable for its emotional impact and certainly not for any explicit action or special effects i rated it an 8 out of 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "KsXE7NAYWyti",
        "outputId": "306fef20-0ca8-464e-a5cc-b6d2ea991479"
      },
      "source": [
        "# Architecture Diagram for LSTM Based Classifcation but you will have to change the\n",
        "# configuration/model parameters while implementing it depending on the input , output and the \n",
        "# Problem statement.\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(url='https://drive.google.com/file/d/1jrO-CJIAf0K5j0duqz2egdx_PyOtbcEW/view?usp=sharing')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://drive.google.com/file/d/1jrO-CJIAf0K5j0duqz2egdx_PyOtbcEW/view?usp=sharing\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R318jVkGWyti",
        "outputId": "c2d93b61-d7e0-4834-ea5f-6cca7363ac2c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Write the code for LSTM Based Classifcation\n",
        "# Embedding layer\n",
        "# LSTM Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# Dense Layer\n",
        "\n",
        "# Students will be starting their code from here:\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Students will be ending their code here\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Change the number of epochs and the batch size depending on the RAM Size\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64,verbose = 1,validation_data=(X_cv,y_cv))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 600, 32)           320000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 373,301\n",
            "Trainable params: 373,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "313/313 [==============================] - 466s 1s/step - loss: 0.6435 - accuracy: 0.6358 - val_loss: 0.3877 - val_accuracy: 0.8376\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 463s 1s/step - loss: 0.3607 - accuracy: 0.8498 - val_loss: 0.3343 - val_accuracy: 0.8612\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 456s 1s/step - loss: 0.2297 - accuracy: 0.9128 - val_loss: 0.3470 - val_accuracy: 0.8624\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 455s 1s/step - loss: 0.1923 - accuracy: 0.9329 - val_loss: 0.3404 - val_accuracy: 0.8656\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 453s 1s/step - loss: 0.1514 - accuracy: 0.9479 - val_loss: 0.3358 - val_accuracy: 0.8728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f819adca198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKrW4GTVWytj",
        "outputId": "6526aa8f-845a-42c0-96b2-7cc28e273b55"
      },
      "source": [
        "# Final evaluation of the model using test dataset\n",
        "# Students will be starting their code from here:\n",
        "scores = model.evaluate(X_test, y_test, verbose=1,batch_size = 256)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98/98 [==============================] - 60s 612ms/step - loss: 0.3705 - accuracy: 0.8608\n",
            "Accuracy: 86.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJt8quWSWytj",
        "outputId": "702cc234-b149-49ac-cdb9-83ce8111561b"
      },
      "source": [
        "# High Level Model Architecture\n",
        "from IPython.display import Image\n",
        "Image(filename='1_VGtBedNuZyX9E-07gnm2Yg.png')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TRadXnCWytk",
        "outputId": "c8f84dff-c92f-42de-ccef-700ff66bb9cc"
      },
      "source": [
        "# create the model\n",
        "embedding_vector_length = 32\n",
        "model = tf.keras.Sequential()\n",
        "# Students will be starting their code from here:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "\n",
        "# Write the code for LSTM Based Classifcation\n",
        "# Embedding layer\n",
        "# Convolution-1D Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# LSTM Layer : You are free to choose the hyperparameters and the number of layers\n",
        "# Dense Layer\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length=max_review_length))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Students will be ending their code here\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "# Change the number of epochs and the batch size depending on the RAM Size\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=64,verbose = 1,validation_data=(X_cv,y_cv))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 600, 32)           320000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 600, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 300, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 376,405\n",
            "Trainable params: 376,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "313/313 [==============================] - 133s 419ms/step - loss: 0.5985 - accuracy: 0.6376 - val_loss: 0.2813 - val_accuracy: 0.8842\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 133s 424ms/step - loss: 0.2247 - accuracy: 0.9150 - val_loss: 0.2863 - val_accuracy: 0.8866\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 131s 420ms/step - loss: 0.1605 - accuracy: 0.9435 - val_loss: 0.2872 - val_accuracy: 0.8878\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 133s 425ms/step - loss: 0.0951 - accuracy: 0.9698 - val_loss: 0.3473 - val_accuracy: 0.8684\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 131s 418ms/step - loss: 0.0687 - accuracy: 0.9796 - val_loss: 0.5080 - val_accuracy: 0.8486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f819765c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK42PQwUWytk",
        "outputId": "583e8f73-7a85-43a1-96ea-852f450f1a97"
      },
      "source": [
        "# Final evaluation of the CNN + RNN model using the test data\n",
        "# Students will be starting their code from here:\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 83.12%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}